{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "126b2cf6",
      "metadata": {
        "id": "126b2cf6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f73cc46",
      "metadata": {
        "id": "5f73cc46"
      },
      "outputs": [],
      "source": [
        "# data preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff7d107",
      "metadata": {
        "id": "1ff7d107"
      },
      "outputs": [],
      "source": [
        "#training image processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b936af18",
      "metadata": {
        "id": "b936af18",
        "outputId": "5d0b08c1-e876-4187-dc6d-dd9a125d3d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8582 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "      rescale =  1./255,\n",
        "      shear_range = 0.2,\n",
        "      zoom_range = 0.2,\n",
        "      horizontal_flip = True)\n",
        "training = train_datagen.flow_from_directory('training',target_size = (128,128),batch_size = 32,class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "903c8ba6",
      "metadata": {
        "id": "903c8ba6"
      },
      "outputs": [],
      "source": [
        "#test image processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8703420",
      "metadata": {
        "id": "d8703420",
        "outputId": "614076f5-bc92-4683-be75-3684120e6582"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1705 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "testing = test_datagen.flow_from_directory('testing',target_size = (128,128),batch_size = 32,class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e9e723",
      "metadata": {
        "id": "99e9e723"
      },
      "outputs": [],
      "source": [
        "#building model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13ee8da8",
      "metadata": {
        "id": "13ee8da8"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e27c9b4",
      "metadata": {
        "id": "8e27c9b4"
      },
      "outputs": [],
      "source": [
        "#building convolution layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93c28e3",
      "metadata": {
        "id": "a93c28e3"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 64,kernel_size = 3, activation = 'relu', input_shape = [128,128,3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2,strides = 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f169975",
      "metadata": {
        "id": "1f169975"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 64,kernel_size = 3, activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2,strides = 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dec1006",
      "metadata": {
        "id": "7dec1006"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 64,kernel_size = 3, activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2,strides = 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16577809",
      "metadata": {
        "id": "16577809"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 64,kernel_size = 3, activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2,strides = 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde5f9f0",
      "metadata": {
        "id": "bde5f9f0"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c266698f",
      "metadata": {
        "id": "c266698f"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "992efe3c",
      "metadata": {
        "id": "992efe3c"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units = 128 , activation = 'relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e5092c",
      "metadata": {
        "id": "a1e5092c"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units = 4, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc27fbd4",
      "metadata": {
        "id": "dc27fbd4"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "923e482a",
      "metadata": {
        "id": "923e482a",
        "outputId": "a60bac26-fcbc-492b-c4c1-529bd4fb2862"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "269/269 [==============================] - 79s 292ms/step - loss: 0.9823 - accuracy: 0.5791 - val_loss: 1.0005 - val_accuracy: 0.6557\n",
            "Epoch 2/30\n",
            "269/269 [==============================] - 68s 252ms/step - loss: 0.6411 - accuracy: 0.7390 - val_loss: 1.1297 - val_accuracy: 0.6991\n",
            "Epoch 3/30\n",
            "269/269 [==============================] - 69s 257ms/step - loss: 0.5045 - accuracy: 0.8009 - val_loss: 0.8303 - val_accuracy: 0.7707\n",
            "Epoch 4/30\n",
            "269/269 [==============================] - 84s 312ms/step - loss: 0.4143 - accuracy: 0.8412 - val_loss: 1.3558 - val_accuracy: 0.7085\n",
            "Epoch 5/30\n",
            "269/269 [==============================] - 131s 489ms/step - loss: 0.3482 - accuracy: 0.8686 - val_loss: 0.8538 - val_accuracy: 0.7689\n",
            "Epoch 6/30\n",
            "269/269 [==============================] - 117s 435ms/step - loss: 0.3006 - accuracy: 0.8897 - val_loss: 1.1115 - val_accuracy: 0.7848\n",
            "Epoch 7/30\n",
            "269/269 [==============================] - 92s 343ms/step - loss: 0.2608 - accuracy: 0.9064 - val_loss: 1.1679 - val_accuracy: 0.8370\n",
            "Epoch 8/30\n",
            "269/269 [==============================] - 86s 318ms/step - loss: 0.2449 - accuracy: 0.9116 - val_loss: 0.7290 - val_accuracy: 0.8669\n",
            "Epoch 9/30\n",
            "269/269 [==============================] - 83s 309ms/step - loss: 0.2269 - accuracy: 0.9197 - val_loss: 0.9908 - val_accuracy: 0.8428\n",
            "Epoch 10/30\n",
            "269/269 [==============================] - 84s 313ms/step - loss: 0.1992 - accuracy: 0.9260 - val_loss: 1.0300 - val_accuracy: 0.8569\n",
            "Epoch 11/30\n",
            "269/269 [==============================] - 80s 296ms/step - loss: 0.1994 - accuracy: 0.9292 - val_loss: 0.7106 - val_accuracy: 0.8821\n",
            "Epoch 12/30\n",
            "269/269 [==============================] - 86s 320ms/step - loss: 0.1710 - accuracy: 0.9388 - val_loss: 0.9647 - val_accuracy: 0.8628\n",
            "Epoch 13/30\n",
            "269/269 [==============================] - 109s 405ms/step - loss: 0.1626 - accuracy: 0.9412 - val_loss: 0.7208 - val_accuracy: 0.8933\n",
            "Epoch 14/30\n",
            "269/269 [==============================] - 80s 296ms/step - loss: 0.1610 - accuracy: 0.9437 - val_loss: 1.0582 - val_accuracy: 0.8809\n",
            "Epoch 15/30\n",
            "269/269 [==============================] - 64s 239ms/step - loss: 0.1442 - accuracy: 0.9498 - val_loss: 0.6528 - val_accuracy: 0.9138\n",
            "Epoch 16/30\n",
            "269/269 [==============================] - 65s 241ms/step - loss: 0.1392 - accuracy: 0.9508 - val_loss: 0.7715 - val_accuracy: 0.9120\n",
            "Epoch 17/30\n",
            "269/269 [==============================] - 65s 240ms/step - loss: 0.1294 - accuracy: 0.9546 - val_loss: 0.9121 - val_accuracy: 0.9109\n",
            "Epoch 18/30\n",
            "269/269 [==============================] - 64s 239ms/step - loss: 0.1276 - accuracy: 0.9554 - val_loss: 1.1542 - val_accuracy: 0.8375\n",
            "Epoch 19/30\n",
            "269/269 [==============================] - 64s 239ms/step - loss: 0.1228 - accuracy: 0.9606 - val_loss: 0.8129 - val_accuracy: 0.9326\n",
            "Epoch 20/30\n",
            "269/269 [==============================] - 66s 245ms/step - loss: 0.1320 - accuracy: 0.9574 - val_loss: 1.0159 - val_accuracy: 0.8733\n",
            "Epoch 21/30\n",
            "269/269 [==============================] - 66s 247ms/step - loss: 0.1122 - accuracy: 0.9620 - val_loss: 1.1820 - val_accuracy: 0.8891\n",
            "Epoch 22/30\n",
            "269/269 [==============================] - 65s 242ms/step - loss: 0.1169 - accuracy: 0.9599 - val_loss: 1.0404 - val_accuracy: 0.8839\n",
            "Epoch 23/30\n",
            "269/269 [==============================] - 64s 239ms/step - loss: 0.1045 - accuracy: 0.9650 - val_loss: 0.8001 - val_accuracy: 0.9255\n",
            "Epoch 24/30\n",
            "133/269 [=============>................] - ETA: 31s - loss: 0.1085 - accuracy: 0.9666"
          ]
        }
      ],
      "source": [
        "cnn.fit(x = training , validation_data = testing, epochs = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de3de9c",
      "metadata": {
        "id": "4de3de9c"
      },
      "outputs": [],
      "source": [
        "#preprocess new image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28ef6a06",
      "metadata": {
        "id": "28ef6a06",
        "outputId": "1ecaddb7-8dd7-4687-9715-a0816da64fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('test_image3.png', target_size = (128,128))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image , axis = 0)\n",
        "result = cnn.predict(test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074b6889",
      "metadata": {
        "id": "074b6889",
        "outputId": "874d2ff7-7888-44a9-9757-e811c49fe3d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "654d581a",
      "metadata": {
        "id": "654d581a",
        "outputId": "147af125-5e07-4e58-9a42-8b70140f050b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf9d78f8",
      "metadata": {
        "id": "cf9d78f8",
        "outputId": "cc9aed85-5177-485c-c400-365923ed4937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meningioma\n"
          ]
        }
      ],
      "source": [
        "if result[0][0] == 1:\n",
        "    print('glioma')\n",
        "elif result[0][1] == 1:\n",
        "    print('meningioma')\n",
        "elif result[0][2] == 1:\n",
        "    print('notumor')\n",
        "elif result[0][3] == 1:\n",
        "    print('pituitary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d42a08e",
      "metadata": {
        "id": "6d42a08e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}